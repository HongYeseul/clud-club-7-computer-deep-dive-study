## 1장 - 프로그래밍 언어부터, 프로그램 실행까지 이렇게 진행된다
----

### 1.1 여러분이 프로그래밍 언어를 발명한다면?

CPU는 개폐(on-off)만 이해하는 매우 원시적인 기계이며 이를 숫자로 표현하면 0과 1

인간과 CPU 사이의 언어가 필요 (CPU의 계산이 빠르고 정확했기 때문)
```
# CPU 관점에서의 코드
1101101010011010
1001001100101001
1l00100011011110
1011101101010010
```
___ 
저수준 언어: 천공카드 -> 어셈블리어
기계어를 통해 간단히 기계어로 인간이 읽고, 그에 대응하는 컴퓨터 언어로 변경하는 바이너리 프로그램 개발 (어셈블리어)
```
# 어셈블리어 코드
sub $8, trsp
mov $.1C0, tedi
call puts
mov $0, Beax
```
___
**사람의 추상적인 언어와 CPU가 이해할 수 있는 구체적인 구현으로 변환할 방법이 필요하다**

<p align="center"><img width="500" alt="image"  src="https://github.com/user-attachments/assets/041880bd-6899-42af-a76e-2844635c9c53" /></p>

고급 프로그래밍 언어
1. 명령의 규칙과 패턴을 statement(문): 만약 ..라면 ..하고, 그렇지 않다면 ...한다 (if, else, while, ..)
2. 중첩된 statement를 syntax(구문): if, else, while, func와 같은 반복되는 문을 간결한 문장으로 표현한 것을 구문이라고 함
3. syntax를 컴퓨터가 이해할 수 있도록 syntax tree(구문트리)로 준비: 전체를 보면 어렵지만 하나의 구문들로 쪼개어 보면 이해할 수 있음
4. compiler가 리프노드부터 재귀적으로 기계명령어로 번역: 맨 아래부터 번역해 부모 노드에 적용해 나가다보면 기계 명령어로 전체를 번역할 수 있고 이에 특화된 소프트웨어를 컴파일러라고 함
<p align="center"><img width="500" alt="image" src="https://github.com/user-attachments/assets/e450fffd-1df6-4672-99b3-6eea365d784c" /></p>

___

해석형 언어: CPU 형식 별로 다른 기계어를 쓰는 문제, 마치 영어가 국제 통용어로 사용되듯이 CPU 형식과 무관한 표준 명령어 집합을 정의하고, CPU의 기계 명령어 실행 과정을 모방하는 프로그램을 따로 준비해서 실행할 수 있음

`모방`한다고 표현한 것은, 표준 명령어로만 실행해도 각 CPU의 특성에 맞는 기계명령어가 실행되는 맥락을 의미한 것. 이러한 CPU 시뮬레이션 프로그램을 가상머신(virtual machie) 혹은 인터프리터(interpreter) 라고 부름.
<p align="center"><img width="445" alt="image" src="https://github.com/user-attachments/assets/a6ff6b9c-0b10-41f0-949d-060ce13c02ba" /></p>

---

### 1.2 컴파일러는 어떻게 작동?
___
컴파일러: 고수준 언어를 저수준 언어로 번역하는 `프로그램`의 일종
소스코드를 입력하면 실행 파일을 반환한다. 텍스트 처리 프로그램 이라고 볼 수도 있다.

소스코드에서 토큰(token)을 추출하는 과정을 어휘 분석(lexical analysis)이라고 한다.
```
    int a = 1;
    int b = 2;
    
    while (a < b)
    {
    	b = b - 1;
    }
# Exchange source code to tokens that is to call lexical analysis
    T_Keyword		int
    T_Identifier 	a
    T_Assign		=
    ...
    (각 행이 하나의 토큰을 의미)
```
그 후 코드가 작성된 구문 문법에 따라 토큰을 해석(parsing)한다. 이 과정에서 문법 오류(syntax error)를 검사한다.

만약, while 구문으로 작성된 코드가 있다면 while 키워드의 토큰을 찾으면 다음 토큰은 ( 여야 한다는 전제 하에 해석을 진행, **해석한 구조를 토대로 `구문 트리`를 생성**한다.

이렇게 트리를 생성하는 전체 과정을 구문 분석이라고 한다.

**생성된 구문트리에 이상이 없는지**를 확인하기 위해 의미분석(semantic analysis)을 실행, 이 과정에서 컴파일 오류를 검사
예를 들어, 정수와 문자열을 더할 수 없고 비교 좌우에 있는 자료형이 다르면 안된다.

구문트리를 탐색한 결과로 중간코드(Intermediate Representation Code, IR Code)를 생성
```
# 중간코드
a=1
b=2
goto B
A: b=b-1
B: if a < b goto A
```

컴파일러는 중간 코드를 가지고, 이를 어셈블리어 -> 기계 명령어의 순서로 변환한다.
```
movl $0x1,-0x4(%rbp)  // a=1
movl $0x2,-0x8(%rbp)  // b=2
...
```
소스코드가 소스파일에 있듯 기계 명령어는 대상파일(object file)에 저장되는데(컴파일 완료), 소스파일 당 대상파일이 존재하며 여러 개의 대상파일을 묶어 하나의 실행파일을 만들기 위해 `링크(link)` 라는 작업이 필요

---

### 1.3 링커의 말할 수 없는 비밀
___



---

### 1.4 컴퓨터 과학에서 추상화가 중요한 이유

---
추상화는 표현력을 향상해 의사소통의 효율을 높이고, 세부 사항을 감춰 내용을 보호하게 해줌.

모듈 기반의 설계에서는 API라는 추상화가 존재.
**각 모듈의 내부구조를 알 필요 없이 프로그래밍이 가능하다.**
프로그래밍 언어는 추상화를 지원하기 위한 자신만의 mechanism 을 제공
> 객체지향 언어(object-oriented programming language)의 경우 다형성과 추상 클래스 등을 이용하여 프로그래머가 쉽게 추상화를 이용
> 프로그래머는 내부 구현이 아닌 추상화만 고려하여 프로그래밍이 가능하고, 이는 확장성 향상과 요구사항 변화에 대응하기 좋음

추상화 예시
- CPU - 트랜지스터들로 구성되어 있지만 명령어 집합(instruction set)이라는 개념으로 내부 세부 사항을 보호 -> 트랜지스터 고려 없이 CPU에 작업 지시
- 기계 명령어 - 고급 프로그래밍 언어
- 입출력 장치 - 파일로 추상화 -> 어느 트랙의 어느 섹터에 저장되는지 고려할 필요가 없다.
- 실행중인 프로그램 -> 프로세스 (CPU 스케쥴링을 고려하지 않아도 독립적으로 CPU를 점유하여 활용)
- 물리 메모리와 파일 -> 가상 메모리 (mmap을 고려하지 않아도 메모리에 독점적 접근 가능)
- 네트워크 프로그래밍 -> 소켓 (네트워크 카드가 어떻게 송수신되는지 고려X)
- 프로세스와 프로세스에 종속적인 실행 환경 -> 컨테이너 (배포 환경 고려할 필요가 없어짐)
- CPU, 운영 체제, 응용 프로그램 -> 가상 머신

**자신만의 프로그램, 고급 프로그래머가 되기 위해선 저수준 계층에 대한 이해가 필요하다.**
