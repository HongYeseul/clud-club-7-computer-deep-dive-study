# 트랜지스터에서 CPU로, 이보다 더 중요한 것은 없다.

## 4.1. 이 작은 장난감을 CPU라고 부른다

### 개요: 논리곱, 논리합, 논리부정

- 이 세 회로로 모든 논리함수를 표현 가능(논리적 완전성: logical completeness)
  - 논리곱 게이트(AND, logical conjunction gate)
  - 논리합 게이트(OR, logical disjunction gate)
  - 논리부정 게이트(NOT, logical negation gate)

### CPU 연산

- CPU의 2진법 덧셈

  - 0 + 0: 결과 0, 자리올림 수 0
  - 0 + 1: 결과 1, 자리올림 수 0
  - 1 + 0: 결과 1, 자리올림 수 0
  - 1 + 1: 결과 0, 자리올림수 1

- 두 입력 값이 서로 다르면 결과가 1, 같으면 0 > 배타적 논리합(XOR, exclusive OR)
- CPU에 전문적으로 계산을 담당하는 모듈 > 산술논리장치(ALU, Arithmetic Logic Unit)

- <b>논리곱 게이트</b>와 <b>베타적 논리합 게이트</b>를 이용한 이진수 덧셈 구현: 가산기
  - <img width="332" alt="Image" src="https://github.com/user-attachments/assets/8a8ca245-7eb0-42b4-b7bf-338248bcf906" />
- <b>부정 논리곱 게이트</b> 두개를 조합 > 정보를 기억하는 회로

  - 부정논리곱: 논리곱 연산 처리 > 논리부정 연산 처리(1,0 > 논리곱 0 > 논리부정 1)
  - <img width="176" alt="Image" src="https://github.com/user-attachments/assets/7903e046-931d-41e9-9618-bc864f232d70" />

- SR래치

### SR 래치 기반 1비트 메모리 저장 회로

1. 회로 구성 목적

- SR 래치를 기반으로 하여 1비트를 저장하는 회로를 구성하고, 입력 단자를 하나로 줄인 효율적인 메모리 회로를 구현한다.
- <img width="378" alt="Image" src="https://github.com/user-attachments/assets/426b47f7-8bd3-48cd-aeb5-82272c07dc25" />

2. SR 래치 기본 동작

| S   | R   | 출력 a       |
| --- | --- | ------------ |
| 1   | 0   | 1 (Set)      |
| 0   | 1   | 0 (Reset)    |
| 0   | 0   | 이전 값 유지 |
| 1   | 1   | 금지 상태    |

- `S`가 1, `R`이 0 → 1 저장
- `S`가 0, `R`이 1 → 0 저장
- `S`, `R` 모두 0 → 현재 값 유지
- `S`, `R` 모두 1 → 금지 (불안정한 상태)

3. SR 래치의 단점

- 정보를 저장하려면 `S`와 `R` 두 신호를 동시에 제어해야 함
- 실제 디지털 시스템에서는 입력 수를 최소화해야 하므로 비효율적임

4. 회로 개선: 입력 단자 하나로 구성

- 입력 신호를 다음과 같이 단순화함:

  - `D` : 저장할 데이터
  - `WE (Write Enable)` : 저장 동작 허용 여부

* AND 게이트 조합으로 SR 신호를 생성:

  - `S = D AND WE`
  - `R = (NOT D) AND WE`

* 동작 표

| D   | WE  | S   | R   | 출력 a 동작 |
| --- | --- | --- | --- | ----------- |
| 0   | 0   | 0   | 0   | 유지        |
| 1   | 0   | 0   | 0   | 유지        |
| 0   | 1   | 0   | 1   | 0 저장      |
| 1   | 1   | 1   | 0   | 1 저장      |

    - `WE = 0`인 경우: 저장 비활성 → 상태 유지
    - `WE = 1`인 경우: `D` 값에 따라 저장됨

5.  요약

- SR 래치를 변형하여 D와 WE 두 입력만으로 1비트 저장 가능
- WE를 통해 쓰기 허용 시점 제어
- 해당 회로는 CPU 및 메모리에서 쓰이는 **기본 저장 소자(래치)** 구성의 핵심

### 소프트웨어와 하드웨어 간 인터페이스: 명령어 집합

- <img width="364" alt="Image" src="https://github.com/user-attachments/assets/98c16dd4-acb8-4057-81e6-b9a230c7946d" />
- 16비트로 구성된 명령어
  - 처음 4비트는 CPU에 수행할 작업 알려줌 > 기계명령어 2^4=16개 설계 가능
- CPU에 덧셈을 수행하라고 지시 > 나머지 비트는 CPU에 어떻게 작업하는지 알려줌
  - R6과 R2의 값을 더한 후 결과를 R6에 저장함

### CPU의 클럭신호와 클럭주파수

1. 클럭신호(Clock Signal)

- **클럭신호란?**  
  디지털 회로에서 모든 연산과 동작이 **일정한 시간 간격**으로 일어나도록 만드는 신호.  
  0과 1이 주기적으로 반복되는 **직사각형 파형(pulse)** 형태의 전기적 신호다.

- **용도**

  - 연산 타이밍 동기화
  - 명령어 실행 순서 제어
  - 레지스터와 메모리 간 데이터 이동 제어

- **예시**  
  클럭이 "1"이 되는 순간(상승 에지 등)에 연산이 수행되거나 저장이 일어남

2. 클럭주파수(Clock Frequency)

- **정의**  
  1초에 몇 번 클럭신호가 반복되는지를 나타내는 수치. 단위는 **Hz(헤르츠)**

- **예시**

  - 3GHz = 1초에 30억 번의 클럭 주기 발생
  - 1GHz = 1초에 10억 번의 클럭 주기 발생

- **클럭 주파수가 높을수록?**
  - 더 많은 명령어를 더 빠르게 실행 가능
  - 하지만 **전력 소모 증가**, **발열 증가**, **설계 복잡성 증가** 등의 단점 존재

3. 클럭 신호 관련 개념

| 용어                | 설명                                     |
| ------------------- | ---------------------------------------- |
| 클럭 사이클 (Cycle) | 클럭신호가 0 → 1 → 0 한 번 반복되는 주기 |
| 클럭 주기 (Period)  | 한 사이클이 걸리는 시간 (1 / 주파수)     |
| 상승 에지           | 클럭신호가 0에서 1로 바뀌는 순간         |
| 하강 에지           | 클럭신호가 1에서 0으로 바뀌는 순간       |

---

4. 요약

- CPU는 클럭신호에 맞춰 **동기식으로 작동**함
- 클럭 주파수는 CPU 성능의 중요한 지표지만, **주파수만이 전부는 아님**
- 클럭 외에도 아키텍처, 명령어 처리 방식, 캐시 효율 등이 성능에 영향을 미침

---

## 4.2. CPU는 유휴 상태일 때 무엇을 할까?

### 대기열 상태 확인: 더 나은 설계

- 프로세스 스케줄링: 운영체제가 프로세스에 우선순위를 할당하고, 이에 따라 스케쥴러가 스케쥴링할 수 있도록 대기열에 프로세스를 넣음
- <img width="379" alt="Image" src="https://github.com/user-attachments/assets/9d512492-6af8-4b02-a70b-50716e8e080b" />

### 연결리스트에서 '감시자'노드 추가: 커널에서의 활용

- 운영체제 커널은 항상 실행 가능한 프로세스를 연결 리스트로 관리함
- 실행 가능한 프로세스가 없을 때를 대비해, 항상 **"유휴 프로세스" (System Idle Process)** 를 리스트에 넣어둠
- 유휴 프로세스는 마치 감시자 노드처럼, **항상 존재하고 준비 상태**를 유지
- 이를 통해 **스케줄러가 예외 없이 항상 실행할 프로세스를 찾을 수 있게 함**

### 요약

- 연결 리스트는 포인터 기반의 순차적 자료구조
- 감시자 노드는 NULL 검사 없이 안전하게 코드를 구성하기 위한 장치
- 커널은 유휴 프로세스를 감시자 노드처럼 사용하여, 빈 프로세스 큐 예외를 막음

### HALT 명령어

1.  정의

- `HALT` 명령어는 **CPU의 동작을 멈추고 대기 상태로 진입**시키는 명령어
- 보통 **운영체제 커널, 펌웨어, 시스템 종료 루틴**에서 사용됨

2. 동작 방식

- HALT가 실행되면 CPU는 **모든 연산을 중단**하고, **다음 인터럽트가 발생할 때까지 대기** 상태에 들어감
- CPU가 멈춘 동안에는 **전력 소비가 줄어들고, 열 발생도 감소**함

3. 사용 예시

- 운영체제 커널에서: 유휴 프로세스가 실행될 때  
  → 시스템에 수행할 작업이 없을 경우, CPU를 HALT 상태로 전환시켜 자원 낭비 방지
- 시스템 종료 시:  
  → OS 종료 이후 더 이상 명령을 수행할 필요가 없을 때 HALT를 실행

4. 특징

- 일반적으로 특권 명령어(Privileged Instruction)로, **커널 모드**에서만 실행 가능
- **사용자 모드(User Mode)**에서 실행 시 예외(Exception)가 발생할 수 있음

---

## 4.3. CPU는 숫자를 어떻게 인식할까?

### 보수법

- [보수 계산 관련](https://velog.io/@c4fiber/1%EC%9D%98-%EB%B3%B4%EC%88%98%EB%B2%95-2%EC%9D%98-%EB%B3%B4%EC%88%98%EB%B2%95)

---

## 4.4. CPU가 if문을 만났을 때

### 파이프라인(Pipeline) 방식 명령어 실행 이해

1. CPU가 하나의 명령어를 실행할 때는 다음의 4단계를 거침

- 1. 명령어 인출 (Instruction Fetch)
- 2. 명령어 해독 (Instruction Decode)
- 3. 실행 (Execute)
- 4. 다시 쓰기 (Writeback)

- 이 4단계는 각각 독립적인 하드웨어에서 수행됨
- 자동차 생산 공정과의 비유: 자동차 한 대를 생산할 때 모든 공정을 하나씩 순차적으로 하면 시간이 오래 걸림. 하지만 공정들을 동시에 분산 처리하면 매 시간마다 새로운 차를 완성할 수 있음
- CPU도 마찬가지: **각 명령어는 동시에 다른 단계를 수행**하므로, 매 사이클마다 새로운 명령어를 처리 가능

2. 파이프라인의 이점

- 단순 순차 처리보다 훨씬 빠름(병렬성을 높여 CPU의 전체 성능을 극적으로 향상시킴)
- 명령어 실행 단계를 **겹쳐서 동시에 처리** → 처리량 증가
- 현대 CPU는 이 방식 덕분에 **초당 수십억 개의 명령어**를 처리할 수 있음

### 분기 에측: 가능한 한 CPU가 올바르게 추측하도록

1. CPU는 조건문(if)을 예측함: 분기 예측(branch prediction)

- CPU는 파이프라인 구조를 사용해 명령어를 연속으로 실행함
- 하지만 조건문(if)이 나오면 흐름이 바뀔 수 있어 **어디로 갈지 미리 예측**해야 함
- 예측이 틀리면 이미 실행한 파이프라인 전부 **무효화(Flush)** → **시간 낭비, 성능 손실 발생**

2. 예측이 쉬운 경우 vs 어려운 경우

- 정렬된 배열 (예측 쉬움)
- 정렬되지 않은 배열 (예측 어려움)
  arr가 정렬되어 있지 않으면 if 결과가 NYNYNY...처럼 랜덤 > CPU가 예측하기 어렵고, 예측 실패로 파이프라인 낭비 증가

3. 분기 최적화(predict hint): likely / unlikely 매크로 (C 언어 등)

- 일부 프로그래밍 언어는 likely(), unlikely() 매크로를 제공
- 이는 컴파일러에게 이 조건이 자주/드물게 발생함을 알려줌
  - likely(x): 조건 x가 자주 true일 것으로 예측 > 정상 흐름일 가능성이 높을 때
  - unlikely(x): 조건 x가 자주 false일 것으로 예측 > 에러, 예외, 드문 조건 처리 루틴 등
