## 5.1 캐시, 어디에나 존재하는 것

### 5.1.1 CPU와 메모리의 속도 차이

> Memory의 속도가 매우 느려 성능 저하 발생 ⇒ 캐시 필요성 대두
> 

**CPU vs Memory**

CPU의 속도가 메모리의 속도보다 훨씬 빠름 ⇒ 시스템 성능은 상대적으로 속도가 느린 쪽에 맞추어 제한

### 5.1.2 도서관, 책상, 캐시

> 캐시를 통한 시스템 성능 향상
> 

**캐시 등장**

최신 CPU는 메모리 사이에 캐시 계층 추가되고, CPU는 메모리에 접근하기 전 캐시 탐색

- 이때 캐시에 명령어와 데이터가 존재하면 메모리에 접근할 필요 없어 실행 속도 크게 향상
    

**캐시**

- 가격이 비싸고 용량이 제한적이지만, 접근 속도가 CPU 속도와 유사
- 최근에 메모리에서 얻은 데이터 저장
- 컴퓨터 시스템 성능 향상에 중요한 역할로, CPU 칩에서 많은 공간 차지

**캐시 구성**

x86과 같은 최신 CPU와 메모리 사이에는 실제로 3단계의 캐시 존재

- L1, L2, L3 캐시와 CPU 코어는 레지스터 칩에 묶여 패키징

캐시 단계에 따라 접근 속도가 느려지지만 용량 증가

1. L1 캐시
    1. 레지스터 접근 속도에 비해 약간 느린 정도 (약 4클럭 주기)
2. L2 캐시
    1. 약 10클럭 주기
3. L3 캐시
    1. 약 50클럭 주기
  

**CPU 동작-캐시 관련**

“L1 → L2 → L3 → 메모리 직접 접근” 순서

메모리에 직접 접근할 때 캐시에 데이터 갱신 ⇒ 이후 메모리에 접근할 필요 X

### 5.1.3 공짜 점심은 없다:캐시 갱신

> 캐시의 단점: 불일치 문제
> 

**Inconsistent(불일치) 문제**

CPU가 Memory가 아닌 Cache에 기록하기 때문에 Memory의 데이터는 아직 예전의 데이터가 남아 있음 **→ 불일치 문제**

**Inconsistent 해결 방법1: write-through(연속 기입)**

Cache 갱신 시 메모리도 함께 갱신 

CPU가 Memory가 갱신될 때까지 대기해야 함 ⇒ Cache-Memory 갱신이 “동기식”

[**동기식 vs 비동기식**](https://www.notion.so/vs-1f0deb6219af802f9b3de0df1b076bf3?pvs=21) 

**Inconsistent 해결 방법2: write-back(후 기입)** 

CPU가 Memory에 기록할 때 Cache 직접 갱신. BUT Memory 갱신을 기다리지 않음

Cache 용량이 부족해 자주 사용되지 않는 데이터 제거할 때 데이터가 수정된 적 있으면 Memory 갱신 ⇒ “비동기식”

write-through보다 훨씬 복잡하지만, 성능 측면에 유리 

### 5.1.4 세상에 공짜 저녁은 없다:다중 코어 캐시의 일관성

> 다중 코어 캐시의 일관성 문제 & 빈번한 다중 코어 캐시 갱신은 성능 문제 야기
> 

**다중 코어 등장**

CPU 성능을 향상시키기 위해 다중 코어 사용

**캐시 불일치 문제**

하나의 변수에 코어1, 코어2가 접근할 때 각각의 캐시 복사본을 가지기 때문에 캐시 불일치 문제 발생

- 해결하기 위해 캐시 한 개에 갱신된 변수가 다른 CPU 코어에도 존재하면 해당 캐시도 함께 갱신되어야 함
- 하지만 빈번하게 다중 코어 캐시의 일관성을 유지하면 성능 문제 발생


### 5.1.5 메모리를 디스크의 캐시로 활용하기

> 디스크 탐색 속도 절감을 위해 메모리를 디스크의 캐시로 사용하는 추세
> 

**디스크**

프로그램이 파일 입출력 시 디스크 문제 발생

디스크 탐색 속도는 메모리 접근 속도에 비해 10만배 느림 → 속도 문제 발생

파일을 읽을 때 데이터를 디스크에서 메모리로 옮겨야 함 → 속도 차이 어떻게 해결해야 할까?

**속도 차이 해결1-공식**

컴퓨터에서 메모리의 일부 공간은 항상 남아 있기 때문에 운영 체제가 여유 메모리 공간을 디스크의 캐시로 활용 ⇒ “리눅스 운영 체제에서 페이지 캐시의 기본 원리”

**속도 차이 해결2-캐시(문제 존재)**

메모리와 디스크 사이 캐시 추가 ⇒ 캐시 갱신 문제 발생

**오늘날 서버 추세**

메모리가 디스크를 대체하는 것이 대세로 RAM 자체가 새로운 디스크 역할 수행

- 메모리가 점점 저렴해지기 때문
- BUT 메모리가 데이터를 영구적으로 저장하는 기능은 없기 때문에 완전히 대체할 수는 없음

### 5.1.6 가상 메모리와 디스크

> 프로세스와 실제 물리 메모리
> 

**개요**

모든 프로세스는 표준 크기의 자체적인 주소 공간을 가지고 해당 주소 공간의 크기는 물리 메모리와 관련이 없음

시스템에 프로레스가 N개 존재하고, 이 N개가 실제 물리 메모리를 모두 사용하고 있는 상황

새로운 프로세스가 생성되어 N+1번째 프로세스로 메모리 요청하는 경우 시스템이 어떻게 처리할 수 있는가

→ 일부 프로세스에서 자주 사용하지 않는 메모리 데이터를 디스크에 기록하고 이 데이터가 차지하던 물리 메모리 공간 해제. 이후 N+1번째 프로세스가 메모리 요청 가능

### 5.1.7 CPU는 어떻게 메모리를 읽을까?

> 운영 체제가 가상 메모리를 사용한다고 가정
> 

**가상 메모리**

CPU가 볼 수 있는 것은 모두 가상 메모리 주소

이 주소가 실제 물리 메모리 주소로 변환되어야 함

변환이 완료되면 캐시 검색

캐시에 존재하지 않으면 메모리 접근

단, 이때 가상 메모리가 존재하기 때문에 프로세스의 데이터가 임시로 보관되어 있을 수 있음 → 해당 데이터를 메모리에서 찾을 수 없을 수 있으며, 디스크의 프로세스 데이터를 메모리에 다시 적재한 후 메모리 읽어야 함

### 5.1.8 분산 저장 지원

> 빅데이터 시대에 단일 장치 디스크만으로 많은 데이터를 완전히 저장할 수 없음
> 

**분산 파일 시스템**

대용량 데이터의 저장 문제를 해결하는 방법

분산 파일 시스템을 mount하고, local disk는 원격의 분산 파일 시스템에서 전송된 파일 저장

- 분산 파일 시스템의 캐시 역할을 local disk가 함

응답 속도를 높이기 위해 원격 분산 파일 시스템의 데이터를 데이터 흐름(data stream) 형태로 직접 로컬 컴퓨터 시스템 메모리로 끌어올 수 있음

- ex. apache kafka

**최신 컴퓨터 시스템 저장 체계**

각 계층이 다음 계층에 대한 캐시 역할

이때 각 계층의 저장 용량은 반드시 다음 계층보다 작아야 함

## 5.2 어떻게 캐시 친화적인 프로그램을 작성할까?

캐시 적중률 향상시키는 방법

### 5.2.1 프로그램 지역성의 원칙

> 프로그램의 지역성의 원칙과 캐시 친화적인 프로그램
> 

**프로그램 지역성의 원칙**

프로그램이 실행될 때 특정 부분이 자주 사용된다는 원칙

“매우 규칙적으로 메모리에 접근”

**시간적 지역성**

캐시 친화성이 매우 높음

**공간적 지역성**

인접한 메모리도 참조 가능

캐시 친화적 ⇒ 캐시가 적중하지 않으면 메모리의 데이터를 캐시에 적재&요청한 메모리의 인접 데이터도 캐시에 저장

### 5.2.2 메모리 풀 사용

> 캐시 친화적인 프로그래밍1: 메모리 풀 사용
> 

**일반적인 메모리 할당**

C, C++ 언어에서는 malloc나 new로 일반적인 상황에서의 메모리 할당

malloc

- 프로그램이 메모리에서 조각을 N개 할당받아야 하는 경우, malloc을 통해 할당받으면 메모리 조각 N개가 힙 영역에 흩어져 있음

malloc 단점

- 복잡
- 공간적 지역성이 좋지 않음

**메모리 풀 기술**

메모리 풀 기술은 일반적으로 고성능 요구 사항이 있을 때만 사용

커다란 메모리 조각을 미리 할당받으며, 이후에는 메모리를 요청하거나 해제할 때 더이상 malloc을 거치지 않음

⇒ 공간적 지역성이 우수하며 캐시 적중률이 훨씬 높아짐

### 5.2.3 struct 구조체 재배치

> 캐시 친화적인 프로그래밍2: struct 구조체 재배치
> 

연결 리스트에 특정 조건을 만족하는 노드가 있는지 판단할 때, next와 value가 빈번히 사용되고 배열 arr은 전혀 사용되지 않음

⇒ next 포인터와 value 값이 배열 arr에 의해 멀리 떨어져 있어 공간 지역성이 나빠지므로 next 포인터와 value 값 연달아 배치

기존

```cpp
#define SIZE 100000

struct List
{
	List* next;
	int arr[SIZE];
	int value;
};
```

재배치

```cpp
#define SIZE 100000

struct List 
{
	List* next;
	int value;
	int arr[SIZE];
};
```

### 5.2.4 핫 데이터와 콜드 데이터의 분리

> 캐시 친화적인 프로그래밍3: 핫 데이터와 콜드 데이터 분리
> 

**상황 가정**

위에서 다뤘듯이 next 포인터와 value 값은 빈번하게 접근하고, arr 배열은 거의 접근하지 않는 경우

프로그래머는 캐시 용량이 제한되어 있음 → 연결 리스트 자체가 차지하는 공간이 클수록 캐시에 저장할 수 있는 노드가 줄어듬. 분리하여 더 나은 지역성 얻을 수 있음

따라서 배열 arr를 다른 구조체에 넣고 List 구조체 안에 구조체를 가리키는 포인터 추가

⇒ arr은 콜드 데이터, next 포인터와 value 값은 핫 데이터

```cpp
#define SIZE 100000

struct List 
{
	List* next;
	int value;
	struct Arr* arr;
};

struct Arr
{
	int arr[SIZE];
};
```

### 5.2.5 캐시 친화적인 데이터 구조

> 캐시 친화적인 구조
> 

**지역성 원칙 관점**

배열이 연결 리스트보다 나음 → 배열은 하나의 연속된 메모리 공간에 할당되지만, 연결 리스트는 일반적으로 흩어져 있을 수 있음

BUT 프로그래밍할 때에는 자료구조가 가지는 장점에 맞추어 선택

최적화할 때 캐시의 적중률이 시스템 성능의 병목이 되는지 판단해야 함. 병목이 되지 않는다면 최적화할 필요 없음

### 5.2.6 다차원 배열 순회

> 지역성 원칙의 고전적인 사례: 다차원 배열 순회 1) 행 우선 방식, 2) 열 우선 방식
> 

**행 우선 방식**

“A0 → A1 → A2 → A3”

2차원 배열 합산 코드: row와 column 순서로 순회하면서 값을 모두 더하는 코드

```cpp
int matrix_summer(int A[M][N])
{
	int i,j,sum=0;
	for (i=0;i<M;i++)
	{
		for (j=0;j<N;j++)
		{
			sum += A[i][j];
		}
	}
	
	return sum;
}
```

C언어는 행 우선 방식으로 배열 저장

1. 행이 4, 열이 8인 경우, 캐시가 최대 4개의 int 데이터 저장 가능

    
2. 순회 시작
    1. 캐시에 배열에 대한 데이터가 없기 때문에 비어 있음 → A0을 포함한 4개가 캐시에 저장
    2. A1-A3까지 메모리에 접근할 필요없음
    
    
3. 캐시 용량 제한으로 A4는 적중할 수 없어 다시 A4를 포함한 4개가 캐시에 저장되어 이전 데이터와 교체
    

즉, 배열에 접근할 때마다 행마다 캐시에 적중할 수 없는 요소가 두 개씩 있으므로 모두 

⇒ 캐시 적중률 75%

**열 우선 방식**

“A0 → A8 → A16 → A24”

```cpp
int matrix_summer(int A[M][N])
{
	int i,j,sum=0;
	for (j=0;j<N;j++)
	{
		for (i=0;i<N;i++)
		{
			sum += A[i][j];
		}
	}
	
	return sum;
}
```

1. A0부터 A3까지 저장
    
2. A8에 접근할 때 위 데이터 버리고 A8-A11까지 다시 저장
3. 이후 A16 접근 시 위 데이터 다시 버리고 A16-A19 저장

⇒ 캐시 적중룔 0%

## 5.3 다중 스레드 성능 방해자

### 5.3.1 캐시와 메모리 상호 작용의 기본 단위:캐시 라인

> Cache Line
> 

**Cache Line**

프로그램이 접근할 데이터만 캐시에 저장하는 것보다 해당 데이터가 있는 곳의 “묶음” 데이터를 캐시에 저장하는 것이 유리

이때의 “묶음” 데이터가 Cache Line

캐시와 메모리 상호 작용의 기본 단위

“묶음” 데이터의 일반적인 크기는 64 바이트

### 5.3.2 첫 번째 성능 방해자:캐시 튕김 문제

> 다중 스레드 프로그램 성능 방해자1: 거짓 공유 문제
> 

**프로그램 1**

두 개의 스레드 시작

각 스레드는 전역 변수 a 를 1씩 5억 번 증가

**프로그램 2**

단일 스레드로 전역 변수 a 1씩 10억 번 증가

**결과**

예상: 첫 번째 프로그램이 두 번째 프로그램의 절반만큼 빠를 것

실제: 두 번째 프로그램이 절반만큼 빠름

**원인**

다중 스레드 프로그램의 insn per cycle은 0.15, 단일 스레드 프로그램의 insn per cycle은 0.6으로 하나의 클럭 주기 동안 실행하는 명령어의 개수가 더 적기 때문

**다중 스레드가 성능이 좋지 않은 이유**

1. 캐시 일관성을 보장하기 위해 두 코어(C1,C2)가 동시에 a 변수를 읽고 쓸 때 변수 무효화 필요 ⇒ 첫 번째 캐시 튕김 발생
    
2. C2는 무효화된 후 다시 메모리에서 a 변수를 읽음
    
3. C2도 변수 변경해야 하므로 C1 캐시 a 변수 무효화 ⇒ 캐시 튕김 발생


이렇게 계속적으로 상대 캐시를 무효화하여 튕겨내기 때문에 성능이 좋지 않음


### 5.3.3 두 번째 성능 방해자:거짓 공유 문제

> 다중 스레드 프로그램 성능 방해자2: 거짓 공유 문제
> 

**프로그램 1**

스레드 두개를 시작한 후 구조체 a 변수와 b 변수를 1씩 각각 5억 번 증가

**프로그램 2**

단일 스레드로 동일하게 a 변수와 b 변수 1씩 5억 번 증가

**결과**

예상: 두 변수를 공유하지 않으므로 캐시 튕김 없고, 프로그램 1이 2배 빠르게 실행될 것

실제: 프로그램1 실행 시간 3초, 프로그램2 실행 시간 2초

**원인**

동일한 Cache Line에 있을 가능성이 높음

캐시와 메모리는 Cache Line 단위로 상호 작용하기 때문에 a 변수가 포함된 Cache Line이 캐시에 저장될 때 b 변수도 함께 저장될 가능성이 매우 높음

**거짓 공유 (false sharing)**

스레드 두 개가 어떤 데이터도 공유하지 않는 것처럼 보이지만, 캐시 동작 방식에 따라 Cache Line 공유

캐시 튕김 문제 발생

**해결 방법**

두 변수 사이에 사용되지 않는 데이터 채워 Cache Line 분리

## More

- **클럭 주기란,**
    
    컴퓨터의 성능은 응답 시간과 처리량으로 나타낼 수 있음
    
    응답 시간 vs CPU 시간
    
    - 응답 시간
        - 작업을 끝내는데 필요한 전체 응답 시간
        - Processing, I/O, OS Overhead, Idle Time 등 모든 시간의 합으로, 매 실행마다 변화 → 응답 시간 대신 정확한 성능 측정을 위한 지표
    - CPU 시간
        - 입출력 시간 등 다른 시간은 제외하고 오직 프로그램 실행을 위해 소비한 시간
    
    클럭(Clock)이란, 
    
    - 컴퓨터가 작업을 수행할 때 일정한 주기
    - 이 박자에 맞춰 CPU 동작
    
    클럭 신호는 “주기”와 “주파수” 속성 존재
    
    - `클럭 주기 (Clock Period, Clock Cycle Time)`
        - 한 사이클에 걸리는 시간. 클럭 주기는 CPU 연산 속도를 결정하는 중요 요소
        - 단위: ps(Pico Second)
    - `클럭 주파수(=속도) (Clock Frequency, Clock Rate)`
        - 1초에 몇 사이클이 도는지. 클럭 주기의 역수
        - 단위: Hz(헤르츠)
    
    따라서 **“총 CPU 시간 = 프로그램의 클럭 사이클 총 수 * 클럭 주기”**
    
- **동기식 vs 비동기식**
    
    동기식 (Synchronous)
    
    - 요청을 보낸 후 해당 요청의 응답을 받아야 다음 동작 실행
    - 순차적으로 실행되어야 하거나 작업의 의존성이 높은 경우 유리
    
    비동기식 (Asynchronous)
    
    - 요청을 보낸 후 응답과 관계없이 다음 동작 실행
    - 시간이 오래 걸리는 작업을 다른 작업과 병렬로 처리하거나 작업의 완료 여부를 기다리지 않고 다른 작업을 실행하는 경우 유리
- **코어, 프로세스, 쓰레드**
    
    코어 (직원으로 비유)
    
    - CPU에서 실제로 연산 작업을 하는 요소
    
    프로세스 (프로젝트로 비유)
    
    - 코어 위에서 동작
    - 독립적인 실행 단위
    - 각자 메모리를 가짐
    
    쓰레드 (모니터로 비유)
    
    - 프로세스 안의 실행 흐름
    - 메모리 공유 및 빠른 실행 가능
    
