## 작은것으로 큰 성과 이루기, 캐시
___

폰 노이만 구조에서, CPU가 실행하는 기계 명령어와 그 명령어가 사용하는 데이터가 모두 메모리에 저장되어있어야 한다.
다시 말해, CPU는 빈번하게 메모리에 접근해 명령어와 데이터를 가져와야 하고, 실행 결과를 메모리에 기록해야 한다.

문제는 속도.
CPU의 연산속도보다 메모리의 접근 속도가 훨씬 느리다. 이러면 CPU의 빠른 연산을 충분히 활용할 수 없다.
-> CPU가 직접 메모리를 읽고 쓰지 않도록 하는 것. 중간에 캐시 계층을 둬 해결할 수 있다.

### 캐시, 어디에나 존재하는 것

- 캐시는 CPU가 사용가능할 만큼 속도가 매우 빠르지만 용량이 제한되어 있다
- 캐시 안에는 최근에 메모리에서 얻은 데이터가 저장된다
- CPU는 명령어/데이터를 꺼내와야 할 때 캐시를 먼저 조회해서 적중하면 메모리에 접근하지 않는다

CPU는 메모리에 직접 읽고 쓰지 않음으로써 메모리와의 속도 차이를 보완한다.

x86 아키텍처에서는 L1, L2, L3 의 캐시 계층이 있다.

<img width="429" alt="스크린샷 2025-05-12 오후 10 02 52" src="https://github.com/user-attachments/assets/4a65b8e3-0936-47e9-bf02-42031d0fc034" />

L1은 4클럭, L2는 10클럭, L3는 50클럭 정도의 주기가 소요된다.
 - 각 명령어는 일정한 클럭(CPU가 한 동작을 수행하는 데 걸리는 기본 단위 시간) 수로 실행된다
 - RISC: 명령어 1개당 1클럭 (이상적 모델)
 - CISC: 명령어 1개에 여러 클럭이 걸릴 수 있음

L1, L2, L3 그리고 CPU 코어는 레지스터 칩 내에 묶여 `패키징`되어있다.
오늘날 CPU 칩에서 상당 부분의 공간을 캐시가 차지한다.

이렇게 캐시 계층을 두면 데이터 조회 성능이 개선되지만, 데이터 기록 시에는 갱신 문제가 발생한다.

- 캐시의 데이터와 메모리의 데이터가 inconsistent(불일치)하는 경우 => 해결 방식은 동기식 설계와 비동기식 설계가 있다.
  - 동기식 - write-through : 캐시를 갱신할 때 메모리도 갱신하는 방법. 불필요한 대기시간 발생.
  - 비동기식 - write-back : 일단 캐시만 갱신하고, 용량 부족으로 캐시가 해제될 때가 되면 그 캐시에 발생했던 수정사항을 메모리에 갱신.
- 다중 코어의 경우, 캐시-메모리 간의 갱신 뿐만 아니라 각 프로세서 캐시들 간의 일관성도 유지되어야 한다.
  - 최신 CPU에는 고전적인 MESI (Flag를 두어 상태를 체크) protocol 같은 것으로 다중 코어의 캐시 일관성을 유지한다. 물론 규칙 적용을 위해서는 성능에 대가가 따른다.
    - Modified(수정) 상태 : 데이터가 수정된 상태
    - Exclusive(배타) 상태 : 유일한 복사본이며, 주기억장치의 내용과 동일한 상태
    - Shared(공유) 상태 : 데이터가 두 개 이상의 프로세서 캐시에 적재되어 있는 상태
    - Invalid(무효) 상태 : 데이터가 다른 프로세스에 의해 수정되어 무효화된 상태

___

메모리와 디스크 간의 속도 차이도 존재한다. 메모리 접근 속도는 디스크 탐색 속도보다 `10만배` 가량 빠르다.

따라서 `메모리 자체를 디스크의 캐시`로 사용한다.
(따로 계층을 추가하지 않는 이유는 메모리의 용량이 캐시로 작용하기에 충분하기 때문)

일반적으로 메모리의 사용률은 100%에 도달하지 않기 때문에, 여유 공간을 디스크를 위한 캐시로 활용한다. 이것이 리눅스에서 `페이지 캐시`의 기본 원리.

여기에도 당연히 `갱신 문제` 즉 `inconsistency` 문제가 발생한다. 이를 위해 여러 입출력 라이브러리들은 `sync`, `flush` 같은 함수를 제공함으로써 `inconsistency`가 발생하기 전에 미리 데이터를 갱신할 방법을 제공한다.

메모리의 가격이 저렴해지면서, 서버에서는 메모리가 디스크를 대체하는 흐름이 있다.

(AWS 에서 2TB 짜리 메모리를 제공하는 instance를 제공)

하지만 이는 "용량 때문에 디스크에 의존해야 했던 상황"을 해결한 것이고, 영속성에 대한 의존은 남아있기 때문에 완전한 대체는 불가능하다.

가상메모리에서 swap-in/out 은 디스크를 일종의 '창고'처럼 활용하는 방법.

<img width="675" alt="스크린샷 2025-05-12 오후 10 27 08" src="https://github.com/user-attachments/assets/0aa95765-c204-4e90-939c-12ab5b4c92bd" />

결국 CPU가 메모리에서 데이터를 읽는 방법은 아래와 같이 정리가 가능하다.

1. 가상 메모리 주소를 실제 물리 주소로 변환.
2. L1, L2, L3 캐시를 검색해서 찾았다면 바로 반환.
3. 못찾았다면 메모리에서 찾아서 반환.
4. 메모리에서도 못찾고 디스크로 swap-out 된 상태이면 디스크에 접근해서 다시 메모리로 적재 후 반환

___
```
분산 파일 시스템 (distributed file system)
대용량 데이터 저장 문제를 해결하는 방법 중 하나로, 데이터를 여러 장치에 나누어 저장하는 것.
```
<img width="461" alt="스크린샷 2025-05-12 오후 10 31 08" src="https://github.com/user-attachments/assets/d18c27c8-3047-493a-8fb8-ae97cece3482" />

원격으로 저장되는 경우에, 원격 분산 파일 시스템에서 전송된 데이터를 로컬 디스크가 저장
이때 로컬 디스크를 `원격 분산 파일 시스템의 캐시`로 볼 수 있음.

더불어, 원격 분산 파일 시스템의 데이터를 data stream 의 형태로 로컬 컴퓨터의 메모리에 끌어올 수도 있음. (apache kafka)
이때는 메모리가 `원격 분산 파일 시스템의 캐시`로 간주됨.

결론: 컴퓨터의 저장 체계의 각 계층이 다음 계층에 대한 캐시 역할을 한다.

단, 각 계층의 저장 용량은 다음 계층의 저장 용량보다 작아야 한다 (그렇지 않으면 그 계층으로 다음 계층을 대체하면 됨)

**컴퓨터 전체 저장 체계가 최대의 성능을 발휘하기 위해선 캐시 친화적인 프로그램을 작성하는 것이 매우 중요.**

___

### 
